
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass{article}

    
    
    \usepackage{graphicx} % Used to insert images
    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{color} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage{ulem} % ulem is needed to support strikethroughs (\sout)
    

    
    
    \definecolor{orange}{cmyk}{0,0.4,0.8,0.2}
    \definecolor{darkorange}{rgb}{.71,0.21,0.01}
    \definecolor{darkgreen}{rgb}{.12,.54,.11}
    \definecolor{myteal}{rgb}{.26, .44, .56}
    \definecolor{gray}{gray}{0.45}
    \definecolor{lightgray}{gray}{.95}
    \definecolor{mediumgray}{gray}{.8}
    \definecolor{inputbackground}{rgb}{.95, .95, .85}
    \definecolor{outputbackground}{rgb}{.95, .95, .95}
    \definecolor{traceback}{rgb}{1, .95, .95}
    % ansi colors
    \definecolor{red}{rgb}{.6,0,0}
    \definecolor{green}{rgb}{0,.65,0}
    \definecolor{brown}{rgb}{0.6,0.6,0}
    \definecolor{blue}{rgb}{0,.145,.698}
    \definecolor{purple}{rgb}{.698,.145,.698}
    \definecolor{cyan}{rgb}{0,.698,.698}
    \definecolor{lightgray}{gray}{0.5}
    
    % bright ansi colors
    \definecolor{darkgray}{gray}{0.25}
    \definecolor{lightred}{rgb}{1.0,0.39,0.28}
    \definecolor{lightgreen}{rgb}{0.48,0.99,0.0}
    \definecolor{lightblue}{rgb}{0.53,0.81,0.92}
    \definecolor{lightpurple}{rgb}{0.87,0.63,0.87}
    \definecolor{lightcyan}{rgb}{0.5,1.0,0.83}
    
    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{Write-ups}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=blue,
      linkcolor=darkorange,
      citecolor=darkgreen,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{Abstract}\label{abstract}

In this article we review the paper ``Statistical analysis of numerical
preclinical radiobiological data''. The work is submitted as a term
project for the Graduate Level Course on Statistical Modelling and
Practices at University of California Berkeley. The authors are graduate
students from department of EECS and Civil\&Environmental Engineering
and have restricted their attention to the methods and analysis done in
the paper. The review is an attempt to reproduce the tests and results
presented in the paper, and discuss some other non-parametric tests and
results eg. Permutation tests, that can be seen as an alternative to
making certain assumptions and finding surprises in the data. No attempt
has been made to look into the biological aspects and validity of
certain assumptions related to them.

    \section{Introduction}\label{introduction}

The paper begins by voicing a growing concern towards ``Scientific fraud
and Plagiarism'' in the scientific community and is successful in
presenting a strong message. To add more\ldots{}..

Before proceeding further, we would like to comment that the
organization of the paper could have been much better with the use of
Sections and Subsections, and re-arranging some of the sections a little
bit.

But the focus of this review is not on the readability and
organizational strucutre, and we pay more attention to reproducing the
results and discussing some more ways of identifying anomaly. In
particular, in Section - \ref{our- analysis} we perform certain tests
that go very well with the spirit of the paper - promoting simple
statistical tools for detecting anomaly.

\subsection{Problem Set Up}\label{problem-set-up}

The authors in the paper analyze anomalous patterns in radiobiological
data from a lab, in particular they were able to detect suspicious
patterns in the data reported by one of the 10 researchers (whom we
shall refer to as RTS as per their notation). They do three different
tests to validate their suspicion and also validate their tests and
assumptions by looking at the data obtained from three other sources. To
dive further, we discuss a bit more in detail about the nature of the
data. Each researcher had to report three different measurements for two
different types of numbers - Colony Count and Coulter Count. Each of
these numbers represents an observation of number of cells surving some
experiment, and probably three measurements are done in order to be more
accurate about the observations. The concern of the authors is that, in
case of fraudolent data, it is easy to fabricate a triplet such that you
get desired mean for that particular set of observations. One can, in
fact, do that by setting the mean and then using two roughly equal
constants, calculate the other two values as this initial value plus or
minus the selected constants. Such a fabrication can be flagged easily
by looking at the triplets and counting how many of them contain the
mean as one of the three values. Having made these observations, the
authors mainly focus ``on developing a method to calculate bounds and
estimates for the probability that a given set of n such triplicates
contains k or more triples which contain their own mean'' and mention
that such probability bounds should be helpful across various other
areas. Under these models they show that RTS's data is pretty surprising
and that the chances of seeing such a data are astronomically low.
Besides this specific set up (which requires some assumptions) they also
look at some more general tests that have been used in the past to
detect anomalous patterns. Namely they test for - (1) Distribution of
the least significant digit, and (2) Chances of observing equal pairs of
terminal digits. Ideally, for (1), we expect to see a uniform
distribution over \(\{0, 1, \ldots, 9\}\) unless the distribution that
underlies the data suggests otherwise. Similarly, for (2), ideal chances
of having an equal pair of terminal digits is 1 in 10.

Next we discuss three major concerns and justify why they were important
to us:

\begin{itemize}
\item
  the paper begins with the RTS being labeled as anomalous and then a
  probability model is developed to determine the chances of seeing the
  mean in a triplet. The authors mentioned briefly that ``Having
  observed what appeared to us to be an unusual frequency of triples in
  RTS data containing a value close to their mean, we used R to
  calculate the mid-ratios for all of the colony data triples that were
  available to us''. The authors didn't comment how were they able to
  identify the particular researcher. Whether they partitioned the data
  into an observation set and then ran tests on the validation set is
  also unclear and the tables tend to hint otherwise. We would like to
  point out that a standard practice is usually to classify the data
  into training and test set. Our concern relies on the well known fact,
  in statistics, that ``the data that raised the suspicion if used to
  validate it, will most likely give a very biased result'';
\item
  the authors also ran tests for the last digit and equality of the pair
  of terminal digits on the datasets, which can be seen as a validation
  of their suspicion. However all the results that are produced are of
  the form ``RTS vs The Rest''. It would have been more convincing if
  the authors presented some justification or some experiment results
  which justified such a treatment. The ideal scenario would have been
  presentation of results in a ``Take - One - Out'' fashion, where every
  individual would have been compared to the rest of them pooled
  together. This is the core principle behind the two sample permutation
  tests, where we test the strong null hypothesis that each researcher's
  data is just a random sample from the population of all the data put
  together. We will dive into this in detail in Section 4;
\item
  there was no discussion about the number of data points across
  researchers. For some reason, the data collected by the RTS had more
  than twice the data put together by twelve other researchers. Such an
  overwhelming fraction of samples belonging to one researcher has some
  implications which we explore in Section 4.
\end{itemize}

In the next section, we touch upon the reproducibility of results. In
Section 3, we discuss our tests and their implications and then make
some final remarks in the Conclusion section.

    \section{Reproducibility of Results}\label{reproducibility-of-results}

In this section, we replicated the statistical experiments that were
conducted by the researchers. There were several mismatches in our first
implementation because of subjectivity at certain places. However, with
some trial and error and fine tuning we were able to replicate most of
their results, obtaining similar results in the other cases. All our
results and code are available at
{[}https://github.com/ianno/stat215a\_project1{]}

    \subsection{Mid-Ratio Analysis}\label{mid-ratio-analysis}

To begin with, the authors first consider the histogram of mid-ratio
which is defined for a triplet \((a, b, c), a<b<c\) as
\(\frac{b-a}{c-a}\), and show that the histogram of RTS concentrates
abnormaly around \(0.4-0.6\) range, compared to everyone else put
together. We tried to reproduce the histogram in python using the
numpy's histogram plots (and in an early test also using Matlab) and it
looked very different. Then, we tweaked the histogram to include the
right edge of the bins and it looked very similar to the Figure(1) of
the paper. But the histogram still had differences, for instance, the
authors get very close to 50\% chance of obtaining a mid-ratio of
0.4-0.5, while we get close to 44\% chance. Also, we used 1361 values
for computing the histogram after removing the triplets with missing
values (in fact, 1360 because one triplet had all equal values) while
the authors used 1343/1361 and provided no justification for the same.
Similarly, we had 595 triplets to plot the histogram for the rest of the
researchers (of the same lab). However, our plots can be categorized
very similar to theirs after the bin adjustment, and we categorized
these differences too minor for investment of more time.

    \subsection{Probability Model}\label{probability-model}

In this section, we followed the equations provided by the authros in
Appendix A to caluclate the probability - lambda table. We could
replicate Table 1 from the paper exactly the same. However as we tried
to increase lambda value to a fairly large one (\textgreater{}1000), the
result that we could get is always 0 even if we chose to use the
logrithm to avoid over floating of the computer. And thus, we could not
verify lambda and corresponding values from around 1000 to 2500, which
was said to be done in the literature. We did observe the probability
started to decrease after lambda reached 4, and after a scanning of the
whole probability values, 0.42, which is stated by the authors, should
be a maximum threehold value.

However, we also came up some arguments about the Poisson assumption for
the micro organism counts. As the samples were taken by the researchers,
and if they did a manual count of the total organisms of the sample,
there are a lot of subjectivity and biases in each of the experiment.
For example, the location of the sight view to count the numbers really
matter, as if the researcher accidentally chose a nutrient-rich
location, the count will be way higher compared to if the sight view is
taken at a relatively nutrient-low location. In addition, certain
microorganisms have such characeristics that they would gather together,
and thus when we do not have very high accuracy equipment, we would
mistakeingly count several cells as one cell, or less cells based on our
arbitary experiences. All of these situations will bring a lot of biases
into the final cell count. Based on that uncertainty, it might not be
precise and accurate to treat the triplet counts as a Poisson triplets,
as there might be dependence between the samples.

" In this section, we tried to replicate what they did in the paper. A
slight difference of the final probabilities were observed in our
calculations compared to their results, where the turning point of
lambda value is around 11, which means the probability keeps increasing
to its maximum value till lambda equals to 11, and then it decreases as
lambda increases. However, we got a similar result for the threhold
value for probability. In the paper, they got 0.42, and we got 0.433. As
their details calculations are not included in this paper, so we
completed the statistical calculations based on their assumptions, such
as the triple is generated by independent, identical Poisson variables
with known parameter lambda includes its own (rounded) mean value. We
applied their assumptions of iid variables for the counts of micro
organisms, and got our results. However, their assumptions may not
always hold at different situations, thus needs further consideration. "

In this section, the researchers from the paper used the lambda values
to calculate the corresponding p-value. They applied a heuristic method
to estimate the actual probability that a given collection of n triples
includes k mean containing tripes to legitimate experimental data, and
such that they are able to confirm the validity of their models, which
is the Poission model. As the true lambda value of the Poisson variables
that generated the triples in the datasets are unknown, they took
advantage of the lambda MidProb table to estimate the true value, based
on the fact that mean of any actural triple is a resonable estimate of
the lambda parameter of the variables. In addition, a Poisson binomial
distribution is assigned to Poisson binominal random variables, which is
the case in their paper. From the characteristics of a poisson binomial
variables, the mean is the sum of all p values, and the standard
deviation is the sum of all p*(1-p) values, which could be used for
further corresponding hypothesis tests. And thus they used this idea to
test the RTS collection of 1343 colony trples, and came to a conclusion
that the probability is an extremely small number, which contradicted
same test results for other investigators.

Several perspectives should be considered when conducting these
statistical tests. We need to check the underlying assumptions such as a
Poisson bernouli variables. One thing to note is that those data has
underlying microbial phenomenna behind them, so when we just treat them
as a number, then we would possibly lose a lot of intrinisic
characteristics of the data. From this logic, the assumption that the
triplets follows a poisson distribution will also be argued, as the
sample would be taken from different growth stage of the organisms,
biases would be introduced to devalidate the Possion assumption, which
lead to the faliure of a Poisson binomial variable assumption.

In addition, the idea of using the existing questionable data to fit a
parameter lambda should be considered further. If there are already
frauds in the existing dataset, it may not be wise to use these data to
fit our parameters. From the same logic, they calculated the mean of the
data, and come up with the corresponding lambda value, which could be
checked to get the p-values. Thus, it implies an idea of using
questionable data to fit parameter, and then use this fitted parameter
to check the questionable data, which is not very scientific.

A detailed regeneration of the method that was applied are listed here:

\begin{quote}
\textbf{\emph{Raaz : Verify the Appendix and comment on the model. }}
\end{quote}

    \subsection{Digits Analysis}\label{digits-analysis}

To find additional confirmations on the suspect of fabricated data, the
authors of the paper perform two additional tests, namely \emph{terminal
digit analysis} and \emph{pair of equal terminal digits analysis}. Both
such analyses are based on the intuition that the least significat digit
of a sample is, in general, not very informative, i.e.~it behaves as a
uniformly distributed random variable. The authors do provide a
reference to a work from J. E. Mosimann, but fail in explaining why such
framework can safely be applied in this context. For instance, there
might be some characteristics of the underlying biological process which
prevent the last digits to be uniformly distributed. An attempt to
clarify and justify this choice in the current setting would have
beneficial. The authors include here additional data, provided by three
external sources (two for Coulter counts and one for Colony counts).
Although the authors comment on the number of these additional samples
in the ``Discussion'' section, we still believe that, in the current
setting, these additional samples do not help them in making a stronger
case, but instead can be misleading and add confusion. As for the
mid-ratio case, we also claim that treating all the other lab
investigator as a single pool is also not sufficient, since uniformity
of the pool doesn't necessarily mean of the single contributors. For
instance, analyzing Table 2 in the paper, it seems that the colony
counts of the other investigators are even \emph{too good}, having a
p-value greater than 0.99. We will elaborate more in next sections.

\subsubsection{Terminal digit analysis}\label{terminal-digit-analysis}

The assumption behind this test is that for experiments including
counts, the last digit of a sample represented by a big number
(\textgreater{}100) can be expected to be uniformly distributed. On the
other hand, fabricated data often fail to show such peculiar property.
The authors use the chi-square test for goodness of fit to demonstrate
the fraudolent nature of RTS' samples.

\begin{figure}[htbp]
\centering
\includegraphics{images/term_repr.png}
\caption{Reproducibility of Terminal Digit Analysis}
\end{figure}

As shown in the above picture, our results are very similar to the ones
in the paper, although not identical.

\subsubsection{Equal digits analysis}\label{equal-digits-analysis}

This test follows from the assumptions made from the previous one, where
here the claim is that in case of genuine data, one should see an equal
pair of terminal digits only in 1/10 of the samples. In this case the
authors consider only big numbers (\textgreater{}100), to ensure the
analysis of only not very significant digits. In this scenario, however,
the authors fail to state what kind of test they have performed (we
assume again chi-square test for goodness) and how the data have been
pre-processed. This led us to obtain similar, but not identical,
results:

\begin{figure}[htbp]
\centering
\includegraphics{images/eq_repr.png}
\caption{Reproducibility of Equal Digits Analysis}
\end{figure}

    \subsubsection{Using lambda to obtain
p-values}\label{using-lambda-to-obtain-p-values}

In this section, the researchers from the paper used the lambda values
to calculate the corresponding p-value. They applied a heuristic method
to estimate the actual probability that a given collection of n triples
includes k mean containing tripes to legitimate experimental data, and
such that they are able to confirm the validity of their models, which
is the Poission model. As the true lambda value of the Poisson variables
that generated the triples in the datasets are unknown, they took
advantage of the lambda MidProb table to estimate the true value, based
on the fact that mean of any actural triple is a resonable estimate of
the lambda parameter of the variables. In addition, a Poisson binomial
distribution is assigned to Poisson binominal random variables, which is
the case in their paper. From the characteristics of a poisson binomial
variables, the mean is the sum of all p values, and the standard
deviation is the sum of all p*(1-p) values, which could be used for
further corresponding hypothesis tests. And thus they used this idea to
test the RTS collection of 1343 colony trples, and came to a conclusion
that the probability is an extremely small number, which contradicted
same test results for other investigators.

\subsubsection{Discussion of
Assumptions}\label{discussion-of-assumptions}

Several perspectives should be considered when conducting these
statistical tests. We need to check the underlying assumptions such as a
Poisson bernouli variables. One thing to note is that those data has
underlying microbial phenomenna behind them, so when we just treat them
as a number, then we would possibly lose a lot of intrinisic
characteristics of the data. From this logic, the assumption that the
triplets follows a poisson distribution will also be argued, as the
sample would be taken from different growth stage of the organisms,
biases would be introduced to devalidate the Possion assumption, which
lead to the faliure of a Poisson binomial variable assumption. In
addition, the idea of using the existing questionable data to fit a
parameter lambda should be considered further. If there are already
frauds in the existing dataset, it may not be wise to use these data to
fit our parameters. From the same logic, they calculated the mean of the
data, and come up with the corresponding lambda value, which could be
checked to get the p-values. Thus, it implies an idea of using
questionable data to fit parameter, and then use this fitted parameter
to check the questionable data, which is not very scientific.

As the data is acquired by different researchers in the biological lab,
a lot of biases would be introduced, such as the skillness of the
researcher to take samples, how fluent they are at this specific task,
different growth situations for micro organisms, how accurate their
instruments are. If we have those biases present in our data, our
assumptions, such as i.i.d variables would not be valiaded, and thus our
corresponding calculations will not be accurate enough. Thus based on
this logic, their reasoning about the difference between the RTS data
and outside lab researcher data analysis should probably be on held.

    \section{Our Analysis}\label{our-analysis}

    The authors single out that the histogram of RTS looks anomalous
compared to the rest of them put together. They assume that one is
likely to observe uniform distribution for mid-ratio, and this fact is
validated by the histogram of the 9 researchers put together which looks
close to uniform. The nautral question is how do we single out the
anomalous resaercher if we don't know apriori who he/she is? A simple
answer would be to plot histogram of the mid-ratios for the data
collected by all researchers invidually, and look for anomalous patterns
across all these plots. For sake of similarity to the authors' set up,
one will detect anomaly by contrasting each researcher's histogram with
the histogram of all others put together. Such an experiment gives very
interesting results and also raises an important issue with this
approach.

\begin{itemize}
\item
  First, histogram for researchers with labels ``B, C, E, H, I'' don't
  seem to be close to uniform as well. In particular, ``B'' and ``C''
  have very different histogram when contrasted with histogram for
  uniform distribution. They have distinct peaks but around 0.2 and 0.4
  respectively.
\item
  Second, when we try to contrast the individual histogram of reseachers
  with rest of them combined which includes RTS now. In the new ``rest''
  histgorams, RTS has a dominating effect because of the comparatively
  huge fraction of data collected by RTS, and so most of the other
  researchers look anomalous when contrasted with it.
\end{itemize}

The previous two remarks point out the limitations on the visual
comparison of histogram and assumption of ``uniform distribution'' for
mid ratios. Next we try to present a different view point which besides
free from such issues, as per our belief can be used in a more general
and broader framework.

\begin{figure}[htbp]
\centering
\includegraphics{images/mid_ratio_hist.png}
\caption{Individual Histograms for the Colony Data}
\end{figure}

    \subsection{Quick Primer to Permutation
Tests}\label{quick-primer-to-permutation-tests}

As discussed in the introduction, we felt that the justification for
singling out the particular RTS was incomplete. So, we took a step back,
and did some tests do identify anomalous patterns across different
researchers. In order to do so, we adapted the philosophy behind
permutation tests.

Given a treatment and control group of size \(T\) and \(C\)
respectively, we want to test the hypothesis if the treatment has an
effect on the population. In permutation test, the data pooled together
is considered as the population (here it will have size \(N = T+C\)).
Next, one decides on a test statistic that is consistent with our
hypothesis and is expected to contrast the two set of samples if the
treatment has any effect. The distribution of test statistic has an
exact theoretical representation but is often computationally
intractable. An empirical approximation can be made by randomly
partitioning the data into groups of \(T\) and \(C\) several times, and
computing the test statistic contrasting the two datasets. With the
distribution in hand, we can now test how surprising was the outcome
that we originally had.

\begin{quote}
*** Antonio, Nigel : Feel Free to Add MORE. It would be nice to have a
Pseduo Code type representation. ***
\end{quote}

    \subsection{Permutation Tests for
Mid-Ratio}\label{permutation-tests-for-mid-ratio}

Because we agree with the remark of the authors that it is easy to tweek
the data to get a desirable triplet, we decide to set the difference in
standard devation of mid-ratios of two datasets.

The choice of standard deviation as the first statistic in place of mean
makes sense because, uniformity as well as convenient tweeking will lead
to same expectation of 0.5; and we expect standard deviation to capture
the ``unintentional reduction in spread caused in data due to
intentional adjustments''.

We consider each researcher equivalent to a treatment. That is, for a
given researcher, eg. A with dataset \(D_A\) with size \(n_A\), we look
at test statistic computed for a random partition of the entire data
(size \(N\)) into two groups \(n_A\) and \(N-n_A\) and compute the test
statistic. We repeat this experiment 1000 times to plot the empirical
distribution and then compute the p-values. We get 0 p-value for A, B,
D, and RTS; and \(<0.01\) p-value for all others except E, which
indicates that almost all datasets are surprising with respect to this
test-statistic. We would like to mention that RTS is still the most
surprising if one looks at the location of the test-statistic in the
tails of the distribution.

Next we look at \(\ell_1\) distance between the density, followed by
\(\ell_1\) distance between the CDF of two samples for each researcher,
and obtain very similar results as in the previous case, that is several
researchers will be rejected by the test at signifiance level of even
\(1 \%\).

    \subsection{Additional Tests for Digit
Analysis}\label{additional-tests-for-digit-analysis}

One of the main concerns we have had is the decision of the authors to
consider the other investigators as a single pool, instead of performing
additional tests on each of them to show that even taken as single
contributors their data still shows the expected behavior. For the
terminal digit and equal digits tests, we extended the tests provided by
the authors by considering the individual contribution of the single
members of the lab and performing: - chi-square test for goodness of fit
for each of the lab members and outside labs for terminal digit
analysis; - chi-square test for goodness of fit for each of the lab
members and outside labs for equal digits analysis; - permutation tests
for terminal digit analysis considering RTS and the other investigators.

    \subsubsection{Chi-square test Tests for Terminal Digit
Analysis}\label{chi-square-test-tests-for-terminal-digit-analysis}

To understand how single investigators contributions are distributed
with respect to RTS and the outside labs, we plotted the histograms of
the individual contributions, both for Coulter and Colony counts:

\begin{figure}[htbp]
\centering
\includegraphics{images/term_plot.png}
\caption{Terminal digit distributions}
\end{figure}

Looking at the plots, it is clear that it is very hard to judge the
quality of the individual contributions, since in none of those cases a
uniform distribution is noticeable. The only conclusion we can easily
state is that the amount of data collected by RTS is incredibly higher
than data collected by others.

To better understand the quality of the data collected by the single
invesitgators in the lab, we performed the chi-square test for goodness
of fit also for each of the individual contributors. The following table
summarized our results:

\begin{figure}[htbp]
\centering
\includegraphics{images/term_inv_tab.png}
\caption{Terminal Digit Analysis}
\end{figure}

Reading the table, one can notice that Investigators C and D (for
Coulter counts) and H (for Colony counts) are also quite low if compared
to the others.

    \subsubsection{Chi-square test Tests for Equal Digits
Analysis}\label{chi-square-test-tests-for-equal-digits-analysis}

Also for the Equal Digits Analysis we performed the chi-square test for
goodness of fit using the data of the individual investigators in the
lab, usign a similar approach than the Terminal Digit Analysis.

Results are summarized in the following table:

\begin{figure}[htbp]
\centering
\includegraphics{images/eq_inv_tab.png}
\caption{Equal Digit Analysis}
\end{figure}

In this case, data from other investigators is more consistent than the
Colony counts, probably because of the higher number of samples
available.

    \subsubsection{Permutation Test for Terminal Digit
Analysis}\label{permutation-test-for-terminal-digit-analysis}

The same considerations we elaborated to justify the permutation tests
statistics for the mid-ratio scenario also hold for the Terminal Digit
Analysis.

The following plots illustrate the permutation tests results using the
\(l-1\) distance between density functions and between CDF's, both for
Coulter and Colony Counts:

\begin{figure}[htbp]
\centering
\includegraphics{images/perm_dens_coulter.png}
\caption{Density distance, Coulter counts}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics{images/perm_cdf_coulter.png}
\caption{CDF distance, Coulter counts}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics{images/perm_dens_colony.png}
\caption{Density distance, Colony counts}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics{images/perm_cdf_colony.png}
\caption{CDF distance, Colony counts}
\end{figure}

In all the above cases, it is possible to see how RTS data is
consistently suspicious, which is a confirmation of the authors'
suspects.

    \section{Conclusion}\label{conclusion}

    Data fraud is an extremely critical issue in science, enginering and
many other fields. Methods to detect manipulated data are needed to
identify fraudulent research behaviors. Detecting frauds, however, is a
delicate matter. Challenging the credibility of a researcher or of a
scentific work, in fact, can have heavy consequences for all the parties
involved in the process. Methodologies and techniques used in this kind
of work need to be clear and widely accepted, and they need to produce
results which do not leave any space to ambiguity. Reproducibily of
results is a fundamental element to rule out any doubts that could arise
at any time. In our review, we carefully analyzed the authors' results
and conclusions by: - reproducing all the results that have been
discussed in the paper; - proposing and implementing additional tests to
clarify doubts and suggesting additional directions to the authors.

We found out that authors' results are correct, although it has not been
possible to reproduce exactly all the experiments due to lack of some
key pieces of information (for instance how data has been
pre-processed). Moreover, we suggested setting up additional tests,
including permutation tests, to clearly understand how every single
investigator's data, besides the RTS, compares to the general data pool.
At the end of our review, we do believe that RTS has fabricated data,
but we suggest the authors to collect additional material and
investigate more, since our tests suggest that other investigators's
data present anomalies as well.

    

    Examples of citations: \protect\hyperlink{cite-PER-GRA:2007}{CITE} or
\protect\hyperlink{cite-Papa2007}{CITE}.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} 
\end{Verbatim}


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
